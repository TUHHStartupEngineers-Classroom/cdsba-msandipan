[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website every time before you want to upload changes."
  },
  {
    "objectID": "content/01_journal/02_statistics.html",
    "href": "content/01_journal/02_statistics.html",
    "title": "Statistical Concepts",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh.\n\n\n\nFor each variable, compute the following values. You can use the built-in functions or use the mathematical formulas.\n\nexpected value\nvariance\nstandard deviation\n\n\n\nlibrary(dplyr)\n#Getting Ages and their Prob\n\nrandom_vars &lt;- readRDS(\"C:/Users/Sandipan Mukherjee/Documents/GitHub/cdsba-msandipan/Causal_Data_Science_Data/random_vars.rds\")\n\nunique_ages&lt;-unique(random_vars[\"age\"]) %&gt;% as.matrix()\nordered_ages&lt;-unique_ages[order(unique_ages, decreasing = FALSE)]\nprob_ages&lt;-prop.table(table(random_vars$age)) %&gt;% unclass()\n\n#Getting Income and their Prob\nunique_inc&lt;-unique(random_vars[\"income\"]) %&gt;% as.matrix()\nordered_inc&lt;-unique_inc[order(unique_inc, decreasing = FALSE)]\nprob_inc&lt;-prop.table(table(random_vars$income)) %&gt;% unclass()\n\nE_ages&lt;-sum(ordered_ages*prob_ages)\nE_inc&lt;-sum(ordered_inc*prob_inc)\n\n#Getting Variance\nVar_ages&lt;-var(random_vars$age)\nVar_inc&lt;-var(random_vars$income)\n\nSd_ages&lt;-sd(random_vars$age)\nSd_inc&lt;-sd(random_vars$income)\n\n\n\n#&gt; [1] \"E(Ages): 33.471\"\n\n\n#&gt; [1] \"E(Income): 3510.731\"\n\n\n#&gt; [1] \"Var(Ages): 340.607766766767\"\n\n\n#&gt; [1] \"Var(Income): 8625645.84448348\"\n\n\n#&gt; [1] \"SD(Ages): 18.4555619466536\"\n\n\n#&gt; [1] \"SD(Income): 2936.94498492626\"\n\n\n\nExplain, if it makes sense to compare the standard deviations.\n\nIt doesn’t make sense to compare the standard deviation. Both have different ranges of values in the population therefor comparisons of just the SD gives us no meaningful information.\n\nThen, examine the relationship between both variables and compute:\n\ncovariance\ncorrelation\n\n\n\nlibrary(dplyr)\n\ncov_data&lt;-cov(random_vars$age,random_vars$income)\ncor_data&lt;-cor(random_vars$age,random_vars$income)\n\n\n\n#&gt; [1] \"Covariance: 29700.1468458458\"\n\n\n#&gt; [1] \"Correlation: 0.547943162326477\"\n\n\n\nWhat measure is easier to interpret? Please discuss your interpretation. Correlation is easier to interpret. Due to the normalization of correlation between -1 to 1 on can precisely determine how strong/weak the relation where has due to the boundless nature of covariance one can only say that the relation between the variables is strong/weak but not its extent.\n\n\nlibrary(dplyr)\n#Set 1\nset1&lt;-random_vars$income[random_vars$age&lt;=18]\n\nunique_inc&lt;-unique(set1) %&gt;% as.matrix()\nordered_inc&lt;-unique_inc[order(unique_inc, decreasing = FALSE)]\nprob_inc&lt;-prop.table(table(set1)) %&gt;% unclass()\n\nE_set1&lt;-sum(ordered_inc*prob_inc)\n\n#Set 2\nset2&lt;-random_vars$income[random_vars$age&gt;=18 & random_vars$age&lt;65]\n\nunique_inc&lt;-unique(set2) %&gt;% as.matrix()\nordered_inc&lt;-unique_inc[order(unique_inc, decreasing = FALSE)]\nprob_inc&lt;-prop.table(table(set2)) %&gt;% unclass()\n\nE_set2&lt;-sum(ordered_inc*prob_inc)\n\n#Set3\nset3&lt;-random_vars$income[random_vars$age&gt;=65]\n\nunique_inc&lt;-unique(set3) %&gt;% as.matrix()\nordered_inc&lt;-unique_inc[order(unique_inc, decreasing = FALSE)]\nprob_inc&lt;-prop.table(table(set3)) %&gt;% unclass()\n\nE_set3&lt;-sum(ordered_inc*prob_inc)\n\n\n\n#&gt; [1] \"E[income|age &lt;= 18]: 389.607438016529\"\n\n\n#&gt; [1] \"E[income|age ∈ [18,65)]: 4685.73426573427\"\n\n\n#&gt; [1] \"E[income|age &gt;= 65]: 1777.23728813559\""
  },
  {
    "objectID": "content/01_journal/04_causality.html",
    "href": "content/01_journal/04_causality.html",
    "title": "Causality",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/09_iv.html",
    "href": "content/01_journal/09_iv.html",
    "title": "Instrumental Variables",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/07_matching.html",
    "href": "content/01_journal/07_matching.html",
    "title": "Matching and Subclassification",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/05_dag.html",
    "href": "content/01_journal/05_dag.html",
    "title": "Directed Acyclic Graphs",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/06_rct.html",
    "href": "content/01_journal/06_rct.html",
    "title": "Randomized Controlled Trials",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/08_did.html",
    "href": "content/01_journal/08_did.html",
    "title": "Difference-in-Differences",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/01_probability.html",
    "href": "content/01_journal/01_probability.html",
    "title": "Probability Theory",
    "section": "",
    "text": "Assuming the same data as in the Probability tree, the related probabilities and their sum is calculate using the code below.\n\n#Constants Definition N&lt;-Not, I&lt;-|. so P(B|A) = P_BIA\nP_S&lt;-0.3\nP_NS&lt;-1-P_S\nP_TIS&lt;-0.2\nP_NTIS&lt;-1-P_TIS\nP_TINS&lt;-0.6\nP_NTINS&lt;-1-P_TINS\n\n#Calculation\nP1&lt;-P_S*P_TIS\nP2&lt;-P_S*P_NTIS\nP3&lt;-P_NS*P_TINS\nP4&lt;-P_NS*P_NTINS\nSum_of_P&lt;-P1+P2+P3+P4\n\n\n\n\nP(T ⋂ S ) = 0.06\nP(T ⋂ !S ) = 0.24\nP(!T ⋂ S ) = 0.42\nP(!T ⋂ !S ) = 0.28\nSum of all = 1"
  },
  {
    "objectID": "content/01_journal/01_probability.html#header-2",
    "href": "content/01_journal/01_probability.html#header-2",
    "title": "Probability Theory",
    "section": "2.1 Header 2",
    "text": "2.1 Header 2\n\nHeader 3\n\nHeader 4\n\nHeader 5\n\nHeader 6"
  },
  {
    "objectID": "content/01_journal/03_regression.html",
    "href": "content/01_journal/03_regression.html",
    "title": "Regression and Statistical Inference",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/10_rdd.html",
    "href": "content/01_journal/10_rdd.html",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/01_probability.html#assumptions",
    "href": "content/01_journal/01_probability.html#assumptions",
    "title": "Probability Theory",
    "section": "",
    "text": "Assuming the same data as in the Probability tree, the related probabilities and their sum is calculate using the code below.\n\n#Constants Definition N&lt;-Not, I&lt;-|. so P(B|A) = P_BIA\nP_S&lt;-0.3\nP_NS&lt;-1-P_S\nP_TIS&lt;-0.2\nP_NTIS&lt;-1-P_TIS\nP_TINS&lt;-0.6\nP_NTINS&lt;-1-P_TINS\n\n#Calculation\nP1&lt;-P_S*P_TIS\nP2&lt;-P_S*P_NTIS\nP3&lt;-P_NS*P_TINS\nP4&lt;-P_NS*P_NTINS\nSum_of_P&lt;-P1+P2+P3+P4"
  },
  {
    "objectID": "content/01_journal/01_probability.html#results",
    "href": "content/01_journal/01_probability.html#results",
    "title": "Probability Theory",
    "section": "",
    "text": "P(T ⋂ S ) = 0.06\nP(T ⋂ !S ) = 0.24\nP(!T ⋂ S ) = 0.42\nP(!T ⋂ !S ) = 0.28\nSum of all = 1"
  }
]